{"cells":[{"cell_type":"code","source":["\nimport pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()\n\narrayArrayData = [\n  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n]\n\ndf = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\ndf.printSchema()\ndf.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"create a DataFrame with a nested array column","showTitle":true,"inputWidgets":{},"nuid":"c9ea4b2d-484f-4143-9f9b-8be7a56acc03"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- subjects: array (nullable = true)\n |    |-- element: array (containsNull = true)\n |    |    |-- element: string (containsNull = true)\n\n+-------+-----------------------------------+\n|name   |subjects                           |\n+-------+-----------------------------------+\n|James  |[[Java, Scala, C++], [Spark, Java]]|\n|Michael|[[Spark, Java, C++], [Spark, Java]]|\n|Robert |[[CSharp, VB], [Spark, Python]]    |\n+-------+-----------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- subjects: array (nullable = true)\n |    |-- element: array (containsNull = true)\n |    |    |-- element: string (containsNull = true)\n\n+-------+-----------------------------------+\n|name   |subjects                           |\n+-------+-----------------------------------+\n|James  |[[Java, Scala, C++], [Spark, Java]]|\n|Michael|[[Spark, Java, C++], [Spark, Java]]|\n|Robert |[[CSharp, VB], [Spark, Python]]    |\n+-------+-----------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import explode\ndf.select(df.name,explode(df.subjects)).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2c70893-f159-497a-a5e1-4d1b6d8e9394"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------------------+\n|name   |col               |\n+-------+------------------+\n|James  |[Java, Scala, C++]|\n|James  |[Spark, Java]     |\n|Michael|[Spark, Java, C++]|\n|Michael|[Spark, Java]     |\n|Robert |[CSharp, VB]      |\n|Robert |[Spark, Python]   |\n+-------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------------------+\n|name   |col               |\n+-------+------------------+\n|James  |[Java, Scala, C++]|\n|James  |[Spark, Java]     |\n|Michael|[Spark, Java, C++]|\n|Michael|[Spark, Java]     |\n|Robert |[CSharp, VB]      |\n|Robert |[Spark, Python]   |\n+-------+------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"\nuse flatten function which converts array of array columns to a single array on DataFrame.\n\"\"\"\n\nfrom pyspark.sql.functions import flatten\ndf.select(df.name,flatten(df.subjects)).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87d468b7-1c65-42d4-bb20-43dd62965ceb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+-------------------------------+\n|name   |flatten(subjects)              |\n+-------+-------------------------------+\n|James  |[Java, Scala, C++, Spark, Java]|\n|Michael|[Spark, Java, C++, Spark, Java]|\n|Robert |[CSharp, VB, Spark, Python]    |\n+-------+-------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+-------------------------------+\n|name   |flatten(subjects)              |\n+-------+-------------------------------+\n|James  |[Java, Scala, C++, Spark, Java]|\n|Michael|[Spark, Java, C++, Spark, Java]|\n|Robert |[CSharp, VB, Spark, Python]    |\n+-------+-------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc506e7d-a98c-4a95-aa6b-cde972ae4e1c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark â€“ explode()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3873296304581795}},"nbformat":4,"nbformat_minor":0}
