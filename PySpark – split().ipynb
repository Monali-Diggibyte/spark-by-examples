{"cells":[{"cell_type":"code","source":["\"\"\"\nPySpark SQL provides split() function to convert delimiter separated String to an Array (StringType to ArrayType) column on DataFrame. This can be done by splitting a string column based on a delimiter like space, comma, pipe e.t.c, and converting it into ArrayType.\n\npyspark.sql.functions.split(str, pattern, limit=-1)\n\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cd21acc-dabe-4fff-a903-046bf5dff514"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n         .appName('SparkByExamples.com') \\\n         .getOrCreate()\n\ndata = [(\"James, A, Smith\",\"2018\",\"M\",3000),\n            (\"Michael, Rose, Jones\",\"2010\",\"M\",4000),\n            (\"Robert,K,Williams\",\"2010\",\"M\",4000),\n            (\"Maria,Anne,Jones\",\"2005\",\"F\",4000),\n            (\"Jen,Mary,Brown\",\"2010\",\"\",-1)\n            ]\n\ncolumns=[\"name\",\"dob_year\",\"gender\",\"salary\"]\n\ndf=spark.createDataFrame(data,columns)\ndf.printSchema()\ndf.show(truncate= False)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"379e12c8-764e-4bdc-885d-e56657677f6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- dob_year: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+--------------------+--------+------+------+\n|name                |dob_year|gender|salary|\n+--------------------+--------+------+------+\n|James, A, Smith     |2018    |M     |3000  |\n|Michael, Rose, Jones|2010    |M     |4000  |\n|Robert,K,Williams   |2010    |M     |4000  |\n|Maria,Anne,Jones    |2005    |F     |4000  |\n|Jen,Mary,Brown      |2010    |      |-1    |\n+--------------------+--------+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- dob_year: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+--------------------+--------+------+------+\n|name                |dob_year|gender|salary|\n+--------------------+--------+------+------+\n|James, A, Smith     |2018    |M     |3000  |\n|Michael, Rose, Jones|2010    |M     |4000  |\n|Robert,K,Williams   |2010    |M     |4000  |\n|Maria,Anne,Jones    |2005    |F     |4000  |\n|Jen,Mary,Brown      |2010    |      |-1    |\n+--------------------+--------+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import split, col\n\ndf2 = df.select('dob_year',split(col(\"name\"),\",\").alias(\"NameArray\"), 'salary' ) \\\n    .drop(\"name\")\ndf2.printSchema()\ndf2.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd0f63ef-34af-4923-868b-1dd072550d1d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- dob_year: string (nullable = true)\n |-- NameArray: array (nullable = true)\n |    |-- element: string (containsNull = false)\n |-- salary: long (nullable = true)\n\n+--------+--------------------+------+\n|dob_year|           NameArray|salary|\n+--------+--------------------+------+\n|    2018| [James,  A,  Smith]|  3000|\n|    2010|[Michael,  Rose, ...|  4000|\n|    2010|[Robert, K, Willi...|  4000|\n|    2005|[Maria, Anne, Jones]|  4000|\n|    2010|  [Jen, Mary, Brown]|    -1|\n+--------+--------------------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- dob_year: string (nullable = true)\n |-- NameArray: array (nullable = true)\n |    |-- element: string (containsNull = false)\n |-- salary: long (nullable = true)\n\n+--------+--------------------+------+\n|dob_year|           NameArray|salary|\n+--------+--------------------+------+\n|    2018| [James,  A,  Smith]|  3000|\n|    2010|[Michael,  Rose, ...|  4000|\n|    2010|[Robert, K, Willi...|  4000|\n|    2005|[Maria, Anne, Jones]|  4000|\n|    2010|  [Jen, Mary, Brown]|    -1|\n+--------+--------------------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\ndf.createOrReplaceTempView(\"PERSON\")\nspark.sql(\"select SPLIT(name,',') as NameArray from PERSON\") \\\n    .show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e88d7a6-78ca-4006-8824-c2e22cd741ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+\n|           NameArray|\n+--------------------+\n| [James,  A,  Smith]|\n|[Michael,  Rose, ...|\n|[Robert, K, Willi...|\n|[Maria, Anne, Jones]|\n|  [Jen, Mary, Brown]|\n+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+\n|           NameArray|\n+--------------------+\n| [James,  A,  Smith]|\n|[Michael,  Rose, ...|\n|[Robert, K, Willi...|\n|[Maria, Anne, Jones]|\n|  [Jen, Mary, Brown]|\n+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"574be7fb-5126-4be1-9806-77bca2a6fb1e"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark â€“ split()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3050953751240851}},"nbformat":4,"nbformat_minor":0}
