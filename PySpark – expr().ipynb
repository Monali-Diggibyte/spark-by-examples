{"cells":[{"cell_type":"code","source":["\"\"\" PySpark SQL expr() (Expression ) Function \"\"\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"854d121e-bc20-424d-a20d-6414ee5122ef"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import expr\n\n#Concatenate columns using || (sql like)\ndata=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")] \ndf=spark.createDataFrame(data).toDF(\"col1\",\"col2\")\n\ndf.show()\ndf.withColumn(\"Name\",expr(\" col1 ||','|| col2\")).show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1af337e5-9e84-435d-9f9a-540fad4577d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+-----+\n| col1| col2|\n+-----+-----+\n|James| Bond|\n|Scott|Varsa|\n+-----+-----+\n\n+-----+-----+-----------+\n| col1| col2|       Name|\n+-----+-----+-----------+\n|James| Bond| James,Bond|\n|Scott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+-----+\n| col1| col2|\n+-----+-----+\n|James| Bond|\n|Scott|Varsa|\n+-----+-----+\n\n+-----+-----+-----------+\n| col1| col2|       Name|\n+-----+-----+-----------+\n|James| Bond| James,Bond|\n|Scott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import expr\ndata = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\ncolumns = [\"name\",\"gender\"]\ndf = spark.createDataFrame(data = data, schema = columns)\n\n#Using CASE WHEN similar to SQL.\nfrom pyspark.sql.functions import expr\n\ndf2=df.withColumn(\"gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\ndf2.show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"060143ff-39bc-463e-98d8-13e0b6b84f41"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+-------+\n|   name| gender|\n+-------+-------+\n|  James|   Male|\n|Michael| Female|\n|    Jen|unknown|\n+-------+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+-------+\n|   name| gender|\n+-------+-------+\n|  James|   Male|\n|Michael| Female|\n|    Jen|unknown|\n+-------+-------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import expr\ndata=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)] \ndf=spark.createDataFrame(data).toDF(\"date\",\"increment\") \ndf.show()\n#Add Month value from another column\ndf.select(df.date,df.increment,\n     expr(\"add_months(date,increment)\")\n  .alias(\"inc_date\")).show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b264816-01f2-4869-86a7-18ceb464b75e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+---------+\n|      date|increment|\n+----------+---------+\n|2019-01-23|        1|\n|2019-06-24|        2|\n|2019-09-20|        3|\n+----------+---------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+---------+\n|      date|increment|\n+----------+---------+\n|2019-01-23|        1|\n|2019-06-24|        2|\n|2019-09-20|        3|\n+----------+---------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\n# Providing alias using 'as'\nfrom pyspark.sql.functions import expr\ndf.select(df.date,df.increment,\n     expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n  ).show()\n# This yields same output as above\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcbac687-2344-440c-810e-ce53db191c30"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nfrom pyspark.sql.functions import expr\n#Concatenate columns\ndata=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")] \ndf=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \ndf.withColumn(\"Name\",expr(\" col1 ||','|| col2\")).show()\n\n#Using CASE WHEN sql expression\ndata = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\ncolumns = [\"name\",\"gender\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf2 = df.withColumn(\"gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\ndf2.show()\n\n#Add months from a value of another column\ndata=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)] \ndf=spark.createDataFrame(data).toDF(\"date\",\"increment\") \ndf.select(df.date,df.increment,\n     expr(\"add_months(date,increment)\")\n  .alias(\"inc_date\")).show()\n\n# Providing alias using 'as'\ndf.select(df.date,df.increment,\n     expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n  ).show()\n\n# Add\ndf.select(df.date,df.increment,\n     expr(\"increment + 5 as new_increment\")\n  ).show()\n\n# Using cast to convert data types\ndf.select(\"increment\",expr(\"cast(increment as string) as str_increment\")) \\\n  .printSchema()\n\n#Use expr()  to filter the rows\ndata=[(100,2),(200,3000),(500,500)] \ndf=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \ndf.filter(expr(\"col1 == col2\")).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66383b02-1f96-4e05-995e-1b314d8c9948"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+-----+-----------+\n| col1| col2|       Name|\n+-----+-----+-----------+\n|James| Bond| James,Bond|\n|Scott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n+-------+-------+\n|   name| gender|\n+-------+-------+\n|  James|   Male|\n|Michael| Female|\n|    Jen|unknown|\n+-------+-------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n+----------+---------+-------------+\n|      date|increment|new_increment|\n+----------+---------+-------------+\n|2019-01-23|        1|            6|\n|2019-06-24|        2|            7|\n|2019-09-20|        3|            8|\n+----------+---------+-------------+\n\nroot\n |-- increment: long (nullable = true)\n |-- str_increment: string (nullable = true)\n\n+----+----+\n|col1|col2|\n+----+----+\n| 500| 500|\n+----+----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+-----+-----------+\n| col1| col2|       Name|\n+-----+-----+-----------+\n|James| Bond| James,Bond|\n|Scott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n+-------+-------+\n|   name| gender|\n+-------+-------+\n|  James|   Male|\n|Michael| Female|\n|    Jen|unknown|\n+-------+-------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n+----------+---------+-------------+\n|      date|increment|new_increment|\n+----------+---------+-------------+\n|2019-01-23|        1|            6|\n|2019-06-24|        2|            7|\n|2019-09-20|        3|            8|\n+----------+---------+-------------+\n\nroot\n |-- increment: long (nullable = true)\n |-- str_increment: string (nullable = true)\n\n+----+----+\n|col1|col2|\n+----+----+\n| 500| 500|\n+----+----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f875e2d6-266c-4917-b24f-301d4ac13747"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – expr()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2394733747941828}},"nbformat":4,"nbformat_minor":0}
